# ============================================
# Papr Memory - Open Source Docker Compose
# ============================================
# Quick Start:
#   1. cp .env.example .env.opensource
#   2. Edit .env.opensource with your API keys (OpenAI, Groq, Deep Infra)
#   3. docker-compose up -d
#   4. Visit http://localhost:5001/docs
#
# Optional Parse Dashboard:
#   docker-compose --profile dashboard up -d parse-dashboard
#   Access at http://localhost:4040 (admin / password)
#
# Temporal Web UI (workflow monitoring):
#   Access at http://localhost:8080
# ============================================

services:

  # Main Papr Memory Application
  papr-memory:
    build:
      context: .
      network: host
    container_name: papr-memory
    image: "${IMAGE_NAME:-papr_memory_oss}:${IMAGE_TAG:-latest}"
    entrypoint: ["/app/scripts/opensource/docker_entrypoint_opensource.sh"]
    command: python main.py
    ports:
      - "5001:5001"
    # volumes:
    #   - ./.env.opensource:/app/.env.opensource  # Disabled: Use docker cp after bootstrap completes
    #   - ./logs:/app/logs  # Optional: mount logs for debugging (requires Docker file sharing)
    env_file:
      - .env.opensource
    environment:
      # Force open source edition
      PAPR_EDITION: opensource
      # Database connections (override .env for Docker networking)
      MONGO_URI: mongodb://${MONGODB_USERNAME:-admin}:${MONGODB_PASSWORD:-password}@mongodb:27017/${MONGODB_DATABASE:-papr_memory}?authSource=admin
      REDIS_URL: redis://:${REDIS_PASSWORD:-password}@redis:6379/0
      NEO4J_URL: bolt://neo4j:7687
      QDRANT_URL: http://qdrant:6333
      # Qdrant collections (auto-selected based on LOCAL_EMBEDDING_DIMENSIONS)
      QDRANT_COLLECTION_QWEN0pt6B: ${QDRANT_COLLECTION_QWEN0pt6B:-Qwen0pt6B}
      QDRANT_COLLECTION_QWEN4B: ${QDRANT_COLLECTION_QWEN4B:-Qwen4B}
      QDRANT_PROPERTY_COLLECTION: ${QDRANT_PROPERTY_COLLECTION:-neo4j_properties_dev}
      # Local embedding configuration (determines which collection is used)
      # Default to false (DeepInfra Qwen 4B) - override with shell var if needed
      USE_LOCAL_EMBEDDINGS: ${USE_LOCAL_EMBEDDINGS:-false}
      LOCAL_EMBEDDING_MODEL: ${LOCAL_EMBEDDING_MODEL:-Qwen/Qwen3-Embedding-4B}
      LOCAL_EMBEDDING_DIMENSIONS: ${LOCAL_EMBEDDING_DIMENSIONS:-2560}
      PARSE_SERVER_URL: ${PARSE_SERVER_URL:-http://parse-server:1337}
      # Parse Server credentials (set both naming conventions for compatibility)
      # Defaults match .env.opensource convention (papr-oss-*)
      PARSE_APPLICATION_ID: ${PARSE_SERVER_APPLICATION_ID:-papr-oss-app-id}
      PARSE_MASTER_KEY: ${PARSE_SERVER_MASTER_KEY:-papr-oss-master-key}
      PARSE_SERVER_APPLICATION_ID: ${PARSE_SERVER_APPLICATION_ID:-papr-oss-app-id}
      PARSE_SERVER_MASTER_KEY: ${PARSE_SERVER_MASTER_KEY:-papr-oss-master-key}
      # Memory Server URL (for open source, set to localhost)
      PYTHON_SERVER_URL: ${PYTHON_SERVER_URL:-http://localhost:5001}
      # SSL certificates - don't set SSL_CERT_FILE (let httpx use system defaults)
      # If SSL_CERT_FILE is set to empty string, httpx will fail
      # The code will auto-detect and set SSL_CERT_FILE only if the file exists
      # Fix protobuf compatibility issue with sentencepiece (BigBird tokenizer)
      # This uses pure-Python protobuf implementation to avoid version conflicts
      PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: python
      # Temporal configuration for durable workflows
      TEMPORAL_ADDRESS: temporal:7233
      TEMPORAL_NAMESPACE: ${TEMPORAL_NAMESPACE:-default}
      TEMPORAL_TASK_QUEUE: ${TEMPORAL_TASK_QUEUE:-memory-processing}
      TEMPORAL_ENABLED: ${TEMPORAL_ENABLED:-true}
    depends_on:
      mongodb:
        condition: service_started
      redis:
        condition: service_started
      neo4j:
        condition: service_healthy  # Wait for Neo4j health check to pass
      qdrant:
        condition: service_started
      parse-server:
        condition: service_started
      temporal:
        condition: service_healthy
    networks:
      - papr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # MongoDB - Primary document storage
  mongodb:
    image: mongo:8.0.12
    container_name: papr-mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
      - mongodb_config:/data/configdb
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGODB_USERNAME:-admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGODB_PASSWORD:-password}
      MONGO_INITDB_DATABASE: ${MONGODB_DATABASE:-papr_memory}
    networks:
      - papr-network
    restart: unless-stopped

  # Redis - Caching layer
  redis:
    image: redis:7-alpine
    container_name: papr-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-password}
    networks:
      - papr-network
    restart: unless-stopped

  # Neo4j - Graph database for memory relationships
  neo4j:
    image: neo4j:2025.10.1
    container_name: papr-neo4j
    ports:
      - "7474:7474"   # HTTP
      - "7687:7687"   # Bolt
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins
    environment:
      NEO4J_AUTH: ${NEO4J_USERNAME:-neo4j}/${NEO4J_PASSWORD:-password}
      NEO4J_PLUGINS: '["apoc"]'
      NEO4J_dbms_security_procedures_unrestricted: "apoc.*"
      NEO4J_dbms_security_procedures_allowlist: "apoc.*"
      NEO4J_dbms_memory_heap_initial__size: "512m"
      NEO4J_dbms_memory_heap_max__size: "2G"
      # Allow connections from Docker network
      NEO4J_dbms_connector_bolt_listen__address: 0.0.0.0:7687
      NEO4J_dbms_connector_http_listen__address: 0.0.0.0:7474
    networks:
      - papr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "password", "RETURN 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Qdrant - Vector database for semantic search
  qdrant:
    image: qdrant/qdrant:v1.16.0
    container_name: papr-qdrant
    ports:
      - "6333:6333"   # HTTP API
      - "6334:6334"   # gRPC API
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
    networks:
      - papr-network
    restart: unless-stopped

  # Parse Server - User management and ACL
  parse-server:
    image: parseplatform/parse-server:8.4.0
    container_name: papr-parse-server
    ports:
      - "1337:1337"
    # volumes:
    #   - parse_data:/parse-server/cloud  # Commented out - no custom cloud code needed for testing
    environment:
      PARSE_SERVER_APPLICATION_ID: ${PARSE_SERVER_APPLICATION_ID:-papr-oss-app-id}
      PARSE_SERVER_MASTER_KEY: ${PARSE_SERVER_MASTER_KEY:-papr-oss-master-key}
      PARSE_SERVER_DATABASE_URI: mongodb://${MONGODB_USERNAME:-admin}:${MONGODB_PASSWORD:-password}@mongodb:27017/${MONGODB_DATABASE:-papr_memory}?authSource=admin
      # Parse Server needs its own URL with /parse mount path (hardcoded, not from env var)
      PARSE_SERVER_URL: http://parse-server:1337/parse
      PARSE_SERVER_PUBLIC_SERVER_URL: http://localhost:1337/parse
      PARSE_SERVER_MOUNT_PATH: /parse
      PARSE_SERVER_ALLOW_ORIGIN: "*"
      # PARSE_SERVER_CLOUD: /parse-server/cloud/main.js  # No cloud code for opensource testing
      PARSE_SERVER_APP_NAME: Papr Memory
      PARSE_SERVER_ENABLE_EXPERIMENTAL_DIRECT_ACCESS: 1
      # Allow class creation during initial setup - can be disabled after schema is initialized
      PARSE_SERVER_ALLOW_CLIENT_CLASS_CREATION: "true"
      PARSE_SERVER_ENABLE_PRIVATE_USERS: "true"
      # Allow custom objectId during object creation (required for search_id functionality)
      # Note: Parse Server 8.x may not support this as an environment variable
      # If this doesn't work, you may need to configure allowCustomObjectId in Parse Server
      # initialization code or use a separate search_id field instead of objectId
      # This allows setting objectId when creating QueryLog entries to match search_id
      PARSE_SERVER_ALLOW_CUSTOM_OBJECT_ID: "true"
      # Parse Server 8.x security settings for local development
      PARSE_SERVER_ALLOW_INSECURE_HTTP: 1
      PARSE_SERVER_ENABLE_CHECK_LOG: 0
      # Allow master key from all sources for local development
      # In production, restrict this to specific IPs
      PARSE_SERVER_MASTER_KEY_IPS: "0.0.0.0/0,::/0"
      # Enable GraphQL API
      PARSE_SERVER_MOUNT_GRAPHQL: "true"
      PARSE_SERVER_MOUNT_PLAYGROUND: "true"
    depends_on:
      - mongodb
    networks:
      - papr-network
    restart: unless-stopped

  # ============================================
  # Temporal - Durable Workflow Engine (Official Setup)
  # ============================================
  # PostgreSQL for Temporal (separate from MongoDB used by app)
  temporal-postgres:
    image: postgres:17-alpine
    container_name: papr-temporal-postgres
    environment:
      POSTGRES_USER: temporal
      POSTGRES_PASSWORD: temporal
    volumes:
      - temporal_postgres_data:/var/lib/postgresql/data
    networks:
      - papr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U temporal"]
      interval: 5s
      timeout: 5s
      retries: 60
      start_period: 30s

  # Temporal Admin Tools - Sets up database schemas
  temporal-admin-tools:
    image: temporalio/admin-tools:1.29.1-tctl-1.18.4-cli-1.5.0
    container_name: papr-temporal-admin-tools
    restart: on-failure:6
    depends_on:
      temporal-postgres:
        condition: service_healthy
    environment:
      - DB=postgres12
      - DB_PORT=5432
      - POSTGRES_USER=temporal
      - POSTGRES_PWD=temporal
      - POSTGRES_SEEDS=temporal-postgres
      - SQL_PASSWORD=temporal
    networks:
      - papr-network
    entrypoint: []
    command:
      - sh
      - -c
      - |
        echo 'Starting PostgreSQL schema setup...'
        echo 'Waiting for PostgreSQL port to be available...'
        nc -z -w 10 temporal-postgres 5432
        echo 'PostgreSQL port is available'
        temporal-sql-tool --plugin postgres12 --ep temporal-postgres -u temporal -p 5432 --db temporal create
        temporal-sql-tool --plugin postgres12 --ep temporal-postgres -u temporal -p 5432 --db temporal setup-schema -v 0.0
        temporal-sql-tool --plugin postgres12 --ep temporal-postgres -u temporal -p 5432 --db temporal update-schema -d /etc/temporal/schema/postgresql/v12/temporal/versioned
        temporal-sql-tool --plugin postgres12 --ep temporal-postgres -u temporal -p 5432 --db temporal_visibility create
        temporal-sql-tool --plugin postgres12 --ep temporal-postgres -u temporal -p 5432 --db temporal_visibility setup-schema -v 0.0
        temporal-sql-tool --plugin postgres12 --ep temporal-postgres -u temporal -p 5432 --db temporal_visibility update-schema -d /etc/temporal/schema/postgresql/v12/visibility/versioned
        echo 'PostgreSQL schema setup complete'

  # Temporal Server - orchestrates durable workflows
  temporal:
    image: temporalio/server:1.29.1
    container_name: papr-temporal
    depends_on:
      temporal-admin-tools:
        condition: service_completed_successfully
    ports:
      - "7233:7233"   # gRPC Frontend
    environment:
      - DB=postgres12
      - DB_PORT=5432
      - POSTGRES_USER=temporal
      - POSTGRES_PWD=temporal
      - POSTGRES_SEEDS=temporal-postgres
      - BIND_ON_IP=0.0.0.0
    networks:
      - papr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "7233"]
      interval: 5s
      timeout: 3s
      start_period: 30s
      retries: 60

  # Temporal Namespace Creator - creates default namespace
  temporal-create-namespace:
    image: temporalio/admin-tools:1.29.1-tctl-1.18.4-cli-1.5.0
    container_name: papr-temporal-create-namespace
    restart: on-failure:5
    depends_on:
      temporal:
        condition: service_healthy
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - DEFAULT_NAMESPACE=default
    networks:
      - papr-network
    entrypoint: []
    command:
      - sh
      - -c
      - |
        echo 'Waiting for Temporal server port to be available...'
        nc -z -w 10 temporal 7233
        echo 'Temporal server port is available'
        echo 'Waiting for Temporal server to be healthy...'
        max_attempts=3
        attempt=0
        until temporal operator cluster health --address temporal:7233; do
          attempt=$$((attempt + 1))
          if [ $$attempt -ge 3 ]; then
            echo 'Server did not become healthy'
            exit 1
          fi
          echo 'Server not ready yet, waiting...'
          sleep 5
        done
        echo 'Server is healthy, creating namespace default...'
        temporal operator namespace describe -n default --address temporal:7233 || temporal operator namespace create -n default --address temporal:7233
        echo 'Namespace default created'

  # Temporal Web UI - Monitor workflows at http://localhost:8080
  temporal-ui:
    image: temporalio/ui:2.34.0
    container_name: papr-temporal-ui
    ports:
      - "8080:8080"
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    depends_on:
      temporal:
        condition: service_healthy
    networks:
      - papr-network
    restart: unless-stopped

  # Temporal Worker - Processes batch memory and document workflows
  temporal-worker:
    build: .
    container_name: papr-temporal-worker
    image: "${IMAGE_NAME:-papr_memory_oss}:${IMAGE_TAG:-latest}"
    command: python start_all_workers.py
    env_file:
      - .env.opensource
    environment:
      PAPR_EDITION: opensource
      # Database connections
      MONGO_URI: mongodb://${MONGODB_USERNAME:-admin}:${MONGODB_PASSWORD:-password}@mongodb:27017/${MONGODB_DATABASE:-papr_memory}?authSource=admin
      REDIS_URL: redis://:${REDIS_PASSWORD:-password}@redis:6379/0
      NEO4J_URL: bolt://neo4j:7687
      NEO4J_USERNAME: ${NEO4J_USERNAME:-neo4j}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-password}
      QDRANT_URL: http://qdrant:6333
      # Qdrant collections (auto-selected based on LOCAL_EMBEDDING_DIMENSIONS)
      QDRANT_COLLECTION_QWEN0pt6B: ${QDRANT_COLLECTION_QWEN0pt6B:-Qwen0pt6B}
      QDRANT_COLLECTION_QWEN4B: ${QDRANT_COLLECTION_QWEN4B:-Qwen4B}
      # Local embedding configuration
      # Default to false (DeepInfra Qwen 4B) - override with shell var if needed
      USE_LOCAL_EMBEDDINGS: ${USE_LOCAL_EMBEDDINGS:-false}
      LOCAL_EMBEDDING_MODEL: ${LOCAL_EMBEDDING_MODEL:-Qwen/Qwen3-Embedding-4B}
      LOCAL_EMBEDDING_DIMENSIONS: ${LOCAL_EMBEDDING_DIMENSIONS:-2560}
      PARSE_SERVER_URL: ${PARSE_SERVER_URL:-http://parse-server:1337}
      PARSE_APPLICATION_ID: ${PARSE_SERVER_APPLICATION_ID:-papr-oss-app-id}
      PARSE_MASTER_KEY: ${PARSE_SERVER_MASTER_KEY:-papr-oss-master-key}
      # Temporal configuration
      TEMPORAL_ADDRESS: temporal:7233
      TEMPORAL_NAMESPACE: ${TEMPORAL_NAMESPACE:-default}
      TEMPORAL_TASK_QUEUE: ${TEMPORAL_TASK_QUEUE:-memory-processing}
      # Disable worker versioning for local Docker testing
      # (versioning requires task queue default build ID to be configured in Temporal)
      TEMPORAL_USE_VERSIONING: "false"
      # Fix protobuf compatibility
      PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: python
    depends_on:
      temporal:
        condition: service_healthy
      mongodb:
        condition: service_started
      redis:
        condition: service_started
      neo4j:
        condition: service_healthy
      qdrant:
        condition: service_started
      parse-server:
        condition: service_started
    networks:
      - papr-network
    restart: unless-stopped

  # Parse Dashboard (Optional - for development)
  # Start with: docker-compose --profile dashboard up -d parse-dashboard
  # Access Parse Dashboard: http://localhost:4040
  # Access GraphQL Console: http://localhost:4040/apps/papr-oss-app-id/api_console/graphql
  # Access GraphQL Playground: http://localhost:1337/playground
  # Login credentials: admin / password
  parse-dashboard:
    image: parseplatform/parse-dashboard:8.0.0
    # Multi-arch image - supports both ARM64 (Apple Silicon) and AMD64 (Intel)
    container_name: papr-parse-dashboard
    ports:
      - "4040:4040"
    command: --dev
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      PARSE_DASHBOARD_TRUST_PROXY: 1
      PARSE_DASHBOARD_COOKIE_SESSION_SECRET: ${PARSE_DASHBOARD_SESSION_SECRET:-your-secret-key}
      PARSE_DASHBOARD_CONFIG: |
        {
          "apps": [
            {
              "serverURL": "http://localhost:1337/parse",
              "graphQLServerURL": "http://localhost:1337/graphql",
              "appId": "papr-oss-app-id",
              "masterKey": "papr-oss-master-key",
              "appName": "Papr Memory",
              "allowInsecureHTTP": true
            }
          ],
          "users": [
            {
              "user": "admin",
              "pass": "$$2b$$10$$/.J.hoDpJjXsJl.deEeeU.bAa8Dgwurprhh2DXheQkjsmNFZEJ7nS"
            }
          ],
          "useEncryptedPasswords": true
        }
    depends_on:
      - parse-server
    networks:
      - papr-network
    restart: unless-stopped
    profiles:
      - dashboard

  # ============================================
  # Test Runner - Runs pytest inside Docker
  # ============================================
  # Usage:
  #   docker compose run --rm test-runner                              (quick test)
  #   docker compose run --rm test-runner pytest tests/test_add_memory_fastapi.py -v  (specific file)
  #   docker compose run --rm test-runner pytest tests/ -v             (all tests)
  #
  # This container does NOT run the server â€” it only runs pytest.
  # The embedding model is loaded once by pytest, so no duplicate memory usage.
  test-runner:
    build:
      context: .
      network: host
    container_name: papr-test-runner
    image: "${IMAGE_NAME:-papr_memory_oss}:${IMAGE_TAG:-latest}"
    entrypoint: []
    command: ["python", "-m", "pytest", "tests/test_add_memory_fastapi.py::test_v1_add_memory_1", "-v", "--tb=short"]
    working_dir: /app
    # Note: Volume mounting is optional. If Docker file sharing is configured,
    # test reports will appear instantly in tests/test_reports/
    # Otherwise, use scripts/run_tests_docker.sh which auto-copies reports
    # volumes:
    #   - .:/app
    env_file:
      - .env.opensource
    environment:
      PAPR_EDITION: opensource
      # Docker service names (these override anything in .env.opensource)
      MONGO_URI: mongodb://${MONGODB_USERNAME:-admin}:${MONGODB_PASSWORD:-password}@mongodb:27017/${MONGODB_DATABASE:-papr_memory}?authSource=admin
      DATABASE_URI: mongodb://${MONGODB_USERNAME:-admin}:${MONGODB_PASSWORD:-password}@mongodb:27017/${MONGODB_DATABASE:-papr_memory}?authSource=admin
      REDIS_URL: redis://:${REDIS_PASSWORD:-password}@redis:6379/0
      NEO4J_URL: bolt://neo4j:7687
      NEO4J_USERNAME: ${NEO4J_USERNAME:-neo4j}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-password}
      QDRANT_URL: http://qdrant:6333
      # Qdrant collections (auto-selected based on LOCAL_EMBEDDING_DIMENSIONS)
      QDRANT_COLLECTION_QWEN0pt6B: ${QDRANT_COLLECTION_QWEN0pt6B:-Qwen0pt6B}
      QDRANT_COLLECTION_QWEN4B: ${QDRANT_COLLECTION_QWEN4B:-Qwen4B}
      # Local embedding configuration
      # Default to false (DeepInfra Qwen 4B) - override with shell var if needed
      USE_LOCAL_EMBEDDINGS: ${USE_LOCAL_EMBEDDINGS:-false}
      LOCAL_EMBEDDING_MODEL: ${LOCAL_EMBEDDING_MODEL:-Qwen/Qwen3-Embedding-4B}
      LOCAL_EMBEDDING_DIMENSIONS: ${LOCAL_EMBEDDING_DIMENSIONS:-2560}
      PARSE_SERVER_URL: ${PARSE_SERVER_URL:-http://parse-server:1337}
      PARSE_APPLICATION_ID: ${PARSE_SERVER_APPLICATION_ID:-papr-oss-app-id}
      PARSE_MASTER_KEY: ${PARSE_SERVER_MASTER_KEY:-papr-oss-master-key}
      PARSE_SERVER_APPLICATION_ID: ${PARSE_SERVER_APPLICATION_ID:-papr-oss-app-id}
      PARSE_SERVER_MASTER_KEY: ${PARSE_SERVER_MASTER_KEY:-papr-oss-master-key}
      PARSE_REST_API_KEY: ${PARSE_SERVER_REST_API_KEY:-papr-oss-rest-key}
      TEMPORAL_ADDRESS: temporal:7233
      TEMPORAL_NAMESPACE: ${TEMPORAL_NAMESPACE:-default}
      TEMPORAL_TASK_QUEUE: ${TEMPORAL_TASK_QUEUE:-memory-processing}
      TEMPORAL_ENABLED: ${TEMPORAL_ENABLED:-true}
      PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: python
      # Prevent OpenBLAS/OpenMP thread conflicts that cause hangs with local embedding models
      OPENBLAS_NUM_THREADS: "1"
      OMP_NUM_THREADS: "1"
      MKL_NUM_THREADS: "1"
      PYTHONPATH: /app
      # Test credentials are auto-fetched from Parse Server at runtime by conftest.py
      # No hardcoded values needed - the bootstrap script creates the test user
    depends_on:
      mongodb:
        condition: service_started
      redis:
        condition: service_started
      neo4j:
        condition: service_started
      qdrant:
        condition: service_started
      parse-server:
        condition: service_started
    networks:
      - papr-network
    profiles:
      - test

volumes:
  mongodb_data:
    driver: local
  mongodb_config:
    driver: local
  redis_data:
    driver: local
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  neo4j_import:
    driver: local
  neo4j_plugins:
    driver: local
  qdrant_data:
    driver: local
  parse_data:
    driver: local
  temporal_postgres_data:
    driver: local

networks:
  papr-network:
    driver: bridge
      